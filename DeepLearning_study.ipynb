{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdlICAQIRzWTikflcvpfV6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jqudes/first-project/blob/master/DeepLearning_study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eKEftAXZ4Sg",
        "outputId": "d5e5b005-3374-4e71-a9ef-38fa32bc2f46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install opencv-contrib-python"
      ],
      "metadata": {
        "id": "0QNHcAgeakjg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3c9fffe-df46-47ef-a3ab-f9d4cceeb1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.8/dist-packages (4.6.0.66)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.8/dist-packages (from opencv-contrib-python) (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "plt.imshow(train_images[0])\n",
        "\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "b3UUBzPUalYw",
        "outputId": "8786ddca-6c10-448a-f4b8-1a6981b26863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 2s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Flatten(input_shape=(28,28)))\n",
        "model.add(layers.Dense(128,activation='relu'))\n",
        "model.add(layers.Dense(10,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('정확도:', test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JUVK0iii9C2",
        "outputId": "b2f7287e-7a1d-4a90-a70a-e99bf9edc7b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 0.4973 - accuracy: 0.8252\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3735 - accuracy: 0.8648\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.3335 - accuracy: 0.8783\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3101 - accuracy: 0.8850\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2952 - accuracy: 0.8912\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3549 - accuracy: 0.8727\n",
            "정확도: 0.8726999759674072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "XxnL9eiojnSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/content/Deeplearning_study/titanic_train.csv\", sep=',')\n",
        "test = pd.read_csv(\"/content/Deeplearning_study/titanic_test.csv\", sep=',')\n",
        "\n",
        "train.drop(['SibSp', 'Parch', 'Ticket', 'Embarked', 'Name', 'Cabin', 'PassengerId', 'Fare', 'Age'], inplace=True, axis=1)\n",
        "\n",
        "train.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "gIEJp3Cpjzsq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = train.groupby('Sex').mean()[\"Survived\"]\n",
        "df.plot(kind='bar')\n",
        "plt.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "EBBjoUu9lDdt",
        "outputId": "f6d80552-fbd5-4b32-f20a-02ae04f3ed48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(*args, **kw)>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DJH2xMVLkU3z",
        "outputId": "e956aa5d-b282-404a-a5ca-ac8665b33803"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass     Sex\n",
              "0         0       3    male\n",
              "1         1       1  female\n",
              "2         1       3  female\n",
              "3         1       1  female\n",
              "4         0       3    male"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1681233e-0d87-44f4-8c9b-2b8bebcf0f7f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>female</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>male</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1681233e-0d87-44f4-8c9b-2b8bebcf0f7f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1681233e-0d87-44f4-8c9b-2b8bebcf0f7f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1681233e-0d87-44f4-8c9b-2b8bebcf0f7f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for ix in train.index:\n",
        "  if train.loc[ix, 'Sex']==\"male\":\n",
        "     train.loc[ix, 'Sex']==1\n",
        "  else:\n",
        "    train.loc[ix, 'Sex']==0\n",
        "\n",
        "target = np.ravel(train.Survived)\n",
        "\n",
        "train.drop(['Survived'], inplace=True, axis=1)\n",
        "train = train.astype(float)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "hS3yQeVUqFm9",
        "outputId": "04a9fe52-df8a-4d37-fff8-de5e13fa40e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-2e04231f2831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   5813\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5814\u001b[0m             \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5815\u001b[0;31m             \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5816\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 418\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"astype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m     def convert(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                     \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_coerce_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;31m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m   1255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1257\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[0;31m# in pandas we don't store numpy str dtypes, so convert to object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0mflat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1096\u001b[0m         \u001b[0;31m# error: Item \"ExtensionArray\" of \"Union[ExtensionArray, ndarray]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0;31m# attribute \"reshape\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m   1199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;31m# Explicit copy, or required since NumPy can't view from / to object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'male'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = kf"
      ],
      "metadata": {
        "id": "fdWlOG25wS6I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#컨벌루션 신경망\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "# 픽셀 값을 0~1 사이로 정규화한다. \n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBN-nmmLzynj",
        "outputId": "33a845e0-8469-4103-ecae-9333f69181b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))"
      ],
      "metadata": {
        "id": "Iyb8jK9K1b-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-JUlStm1oGY",
        "outputId": "e971191e-2038-4dbc-dbbe-b9e7970550ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 13, 13, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 11, 11, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 5, 5, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 3, 3, 64)          36928     \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                36928     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('./data/model/my_model.dls1')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e13m8qH31qQ_",
        "outputId": "ef977fe1-e8d9-4cbf-f2bc-e68882a917ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#14.모델 성능 향상시키기 \n",
        "\n",
        "import pandas as pd\n",
        "!git clone https://github.com/taehojo/data/git    #링크에 데이터 없음\n",
        "\n",
        "df=pd.read_csv('./data/wine.csv', header=None)\n",
        "\n",
        "df #데이터를 미리 확인"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "KAc2Fm9e1yhU",
        "outputId": "f180b7d4-67f4-4385-e627-410cd2ea1614"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'git'...\n",
            "remote: Not Found\n",
            "fatal: repository 'https://github.com/taehojo/data/git/' not found\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-64217cf848ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/taehojo/data/git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data/wine.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;31m#데이터를 미리 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/wine.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# !git clone https://github.com/taehojo/data/git  #아래줄과 둘중 하나만 돌리면 된다.\n",
        "\n",
        "df = pd.read_csv('/content/Deeplearning_study/wine.csv', header=None)\n",
        "\n",
        "X=df.iloc[:,0:12]\n",
        "y=df.iloc[:,12]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model= Sequential()\n",
        "\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25)\n",
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cd0y4KwP4N9F",
        "outputId": "7b00c5e4-f117-4f15-c5de-c030a065c1f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 30)                390       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 12)                372       \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "8/8 [==============================] - 1s 36ms/step - loss: 12.3442 - accuracy: 0.2428 - val_loss: 8.6049 - val_accuracy: 0.2477\n",
            "Epoch 2/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 7.7870 - accuracy: 0.2428 - val_loss: 6.4252 - val_accuracy: 0.2477\n",
            "Epoch 3/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 5.9719 - accuracy: 0.2428 - val_loss: 5.1548 - val_accuracy: 0.2477\n",
            "Epoch 4/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4.7478 - accuracy: 0.2428 - val_loss: 3.9993 - val_accuracy: 0.2477\n",
            "Epoch 5/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3.6052 - accuracy: 0.2428 - val_loss: 2.9297 - val_accuracy: 0.2477\n",
            "Epoch 6/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 2.5795 - accuracy: 0.2428 - val_loss: 2.0202 - val_accuracy: 0.2477\n",
            "Epoch 7/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 1.7639 - accuracy: 0.2430 - val_loss: 1.4067 - val_accuracy: 0.2477\n",
            "Epoch 8/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 1.2095 - accuracy: 0.2422 - val_loss: 0.9241 - val_accuracy: 0.2677\n",
            "Epoch 9/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.7226 - accuracy: 0.4647 - val_loss: 0.4709 - val_accuracy: 0.8046\n",
            "Epoch 10/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.4100 - accuracy: 0.8214 - val_loss: 0.4106 - val_accuracy: 0.8162\n",
            "Epoch 11/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3952 - accuracy: 0.8355 - val_loss: 0.4054 - val_accuracy: 0.8523\n",
            "Epoch 12/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3770 - accuracy: 0.8666 - val_loss: 0.3773 - val_accuracy: 0.8769\n",
            "Epoch 13/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.3559 - accuracy: 0.8899 - val_loss: 0.3623 - val_accuracy: 0.9038\n",
            "Epoch 14/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3443 - accuracy: 0.9071 - val_loss: 0.3488 - val_accuracy: 0.9108\n",
            "Epoch 15/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.3312 - accuracy: 0.9112 - val_loss: 0.3361 - val_accuracy: 0.9123\n",
            "Epoch 16/50\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3199 - accuracy: 0.9153 - val_loss: 0.3251 - val_accuracy: 0.9146\n",
            "Epoch 17/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.3093 - accuracy: 0.9187 - val_loss: 0.3134 - val_accuracy: 0.9154\n",
            "Epoch 18/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2993 - accuracy: 0.9207 - val_loss: 0.3032 - val_accuracy: 0.9192\n",
            "Epoch 19/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2897 - accuracy: 0.9243 - val_loss: 0.2944 - val_accuracy: 0.9223\n",
            "Epoch 20/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2812 - accuracy: 0.9258 - val_loss: 0.2855 - val_accuracy: 0.9262\n",
            "Epoch 21/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2735 - accuracy: 0.9284 - val_loss: 0.2777 - val_accuracy: 0.9254\n",
            "Epoch 22/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2665 - accuracy: 0.9310 - val_loss: 0.2704 - val_accuracy: 0.9285\n",
            "Epoch 23/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2597 - accuracy: 0.9315 - val_loss: 0.2633 - val_accuracy: 0.9285\n",
            "Epoch 24/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2534 - accuracy: 0.9325 - val_loss: 0.2558 - val_accuracy: 0.9300\n",
            "Epoch 25/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2467 - accuracy: 0.9325 - val_loss: 0.2479 - val_accuracy: 0.9292\n",
            "Epoch 26/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2391 - accuracy: 0.9323 - val_loss: 0.2391 - val_accuracy: 0.9308\n",
            "Epoch 27/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2309 - accuracy: 0.9338 - val_loss: 0.2309 - val_accuracy: 0.9323\n",
            "Epoch 28/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.2241 - accuracy: 0.9346 - val_loss: 0.2242 - val_accuracy: 0.9354\n",
            "Epoch 29/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2182 - accuracy: 0.9361 - val_loss: 0.2184 - val_accuracy: 0.9362\n",
            "Epoch 30/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.9366 - val_loss: 0.2133 - val_accuracy: 0.9346\n",
            "Epoch 31/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.2088 - accuracy: 0.9366 - val_loss: 0.2091 - val_accuracy: 0.9354\n",
            "Epoch 32/50\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.2048 - accuracy: 0.9392 - val_loss: 0.2042 - val_accuracy: 0.9362\n",
            "Epoch 33/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.2013 - accuracy: 0.9394 - val_loss: 0.2005 - val_accuracy: 0.9362\n",
            "Epoch 34/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1979 - accuracy: 0.9387 - val_loss: 0.1972 - val_accuracy: 0.9362\n",
            "Epoch 35/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1949 - accuracy: 0.9405 - val_loss: 0.1924 - val_accuracy: 0.9385\n",
            "Epoch 36/50\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1907 - accuracy: 0.9400 - val_loss: 0.1879 - val_accuracy: 0.9369\n",
            "Epoch 37/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1864 - accuracy: 0.9397 - val_loss: 0.1827 - val_accuracy: 0.9400\n",
            "Epoch 38/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1827 - accuracy: 0.9402 - val_loss: 0.1770 - val_accuracy: 0.9408\n",
            "Epoch 39/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1775 - accuracy: 0.9415 - val_loss: 0.1752 - val_accuracy: 0.9400\n",
            "Epoch 40/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1758 - accuracy: 0.9423 - val_loss: 0.1697 - val_accuracy: 0.9415\n",
            "Epoch 41/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1717 - accuracy: 0.9438 - val_loss: 0.1650 - val_accuracy: 0.9438\n",
            "Epoch 42/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1699 - accuracy: 0.9428 - val_loss: 0.1621 - val_accuracy: 0.9469\n",
            "Epoch 43/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1659 - accuracy: 0.9471 - val_loss: 0.1608 - val_accuracy: 0.9431\n",
            "Epoch 44/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1640 - accuracy: 0.9451 - val_loss: 0.1581 - val_accuracy: 0.9462\n",
            "Epoch 45/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1617 - accuracy: 0.9484 - val_loss: 0.1566 - val_accuracy: 0.9438\n",
            "Epoch 46/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1599 - accuracy: 0.9471 - val_loss: 0.1533 - val_accuracy: 0.9469\n",
            "Epoch 47/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1580 - accuracy: 0.9459 - val_loss: 0.1518 - val_accuracy: 0.9492\n",
            "Epoch 48/50\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9477 - val_loss: 0.1493 - val_accuracy: 0.9485\n",
            "Epoch 49/50\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1549 - accuracy: 0.9471 - val_loss: 0.1527 - val_accuracy: 0.9423\n",
            "Epoch 50/50\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1539 - accuracy: 0.9500 - val_loss: 0.1458 - val_accuracy: 0.9500\n",
            "41/41 [==============================] - 0s 2ms/step - loss: 0.1484 - accuracy: 0.9446\n",
            "Test accuracy: 0.944615364074707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# !git clone https://github.com/taehojo/data/git  #아래줄과 둘중 하나만 돌리면 된다.\n",
        "\n",
        "df = pd.read_csv('/content/Deeplearning_study/wine.csv', header=None)\n",
        "\n",
        "X=df.iloc[:,0:12]\n",
        "y=df.iloc[:,12]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model= Sequential()\n",
        "\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "modelpath = \"/content/Deeplearning_study/{epoch:02d}-{val_accuracy: .4f}.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, verbose=1)\n",
        "\n",
        "history =model.fit(X_train, y_train, epochs=50, batch_size=500, validation_split=0.25, verbose=0, callbacks=[checkpointer])\n",
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy', score[1])"
      ],
      "metadata": {
        "id": "ePBmxZ_w6QzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# !git clone https://github.com/taehojo/data/git  #아래줄과 둘중 하나만 돌리면 된다.\n",
        "\n",
        "df = pd.read_csv('/content/Deeplearning_study/wine.csv', header=None)\n",
        "\n",
        "X=df.iloc[:,0:12]\n",
        "y=df.iloc[:,12]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, shuffle=True)\n",
        "\n",
        "model= Sequential()\n",
        "\n",
        "model.add(Dense(30, input_dim=12, activation='relu'))\n",
        "model.add(Dense(12, activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "modelpath = \"/content/Deeplearning_study/Ch14-4-bestmodel.hdf5\"\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "history =model.fit(X_train, y_train, epochs=2000, batch_size=500, validation_split=0.25, verbose=1, callbacks=[early_stopping_callback, checkpointer])\n",
        "\n",
        "score = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5GV4eYEN9Dti",
        "outputId": "4b97efba-9f07-4838-b75a-50211628a359"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_34 (Dense)            (None, 30)                390       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 12)                372       \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 1)                 9         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 875\n",
            "Trainable params: 875\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "8/8 [==============================] - 5s 225ms/step - loss: 0.6655 - accuracy: 0.8006 - val_loss: 0.3130 - val_accuracy: 0.8677\n",
            "Epoch 2/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.3772 - accuracy: 0.8594 - val_loss: 0.3495 - val_accuracy: 0.8869\n",
            "Epoch 3/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3389 - accuracy: 0.8781 - val_loss: 0.2726 - val_accuracy: 0.8908\n",
            "Epoch 4/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.3127 - accuracy: 0.8781 - val_loss: 0.2283 - val_accuracy: 0.9231\n",
            "Epoch 5/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2658 - accuracy: 0.9112 - val_loss: 0.2236 - val_accuracy: 0.9269\n",
            "Epoch 6/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2495 - accuracy: 0.9166 - val_loss: 0.1970 - val_accuracy: 0.9346\n",
            "Epoch 7/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2410 - accuracy: 0.9230 - val_loss: 0.1951 - val_accuracy: 0.9392\n",
            "Epoch 8/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2334 - accuracy: 0.9251 - val_loss: 0.1866 - val_accuracy: 0.9400\n",
            "Epoch 9/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2292 - accuracy: 0.9246 - val_loss: 0.1825 - val_accuracy: 0.9438\n",
            "Epoch 10/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2247 - accuracy: 0.9266 - val_loss: 0.1777 - val_accuracy: 0.9431\n",
            "Epoch 11/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2204 - accuracy: 0.9269 - val_loss: 0.1748 - val_accuracy: 0.9469\n",
            "Epoch 12/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.2168 - accuracy: 0.9281 - val_loss: 0.1725 - val_accuracy: 0.9454\n",
            "Epoch 13/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.2158 - accuracy: 0.9271 - val_loss: 0.1707 - val_accuracy: 0.9492\n",
            "Epoch 14/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.2059 - accuracy: 0.9317 - val_loss: 0.1655 - val_accuracy: 0.9469\n",
            "Epoch 15/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.2002 - accuracy: 0.9297 - val_loss: 0.1592 - val_accuracy: 0.9446\n",
            "Epoch 16/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1953 - accuracy: 0.9305 - val_loss: 0.1585 - val_accuracy: 0.9477\n",
            "Epoch 17/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1899 - accuracy: 0.9320 - val_loss: 0.1537 - val_accuracy: 0.9485\n",
            "Epoch 18/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1868 - accuracy: 0.9338 - val_loss: 0.1529 - val_accuracy: 0.9462\n",
            "Epoch 19/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1856 - accuracy: 0.9335 - val_loss: 0.1499 - val_accuracy: 0.9508\n",
            "Epoch 20/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1794 - accuracy: 0.9358 - val_loss: 0.1492 - val_accuracy: 0.9508\n",
            "Epoch 21/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1758 - accuracy: 0.9374 - val_loss: 0.1467 - val_accuracy: 0.9508\n",
            "Epoch 22/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1729 - accuracy: 0.9382 - val_loss: 0.1486 - val_accuracy: 0.9508\n",
            "Epoch 23/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1716 - accuracy: 0.9379 - val_loss: 0.1410 - val_accuracy: 0.9500\n",
            "Epoch 24/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1682 - accuracy: 0.9394 - val_loss: 0.1382 - val_accuracy: 0.9515\n",
            "Epoch 25/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1671 - accuracy: 0.9389 - val_loss: 0.1373 - val_accuracy: 0.9523\n",
            "Epoch 26/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1672 - accuracy: 0.9400 - val_loss: 0.1340 - val_accuracy: 0.9515\n",
            "Epoch 27/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1672 - accuracy: 0.9392 - val_loss: 0.1368 - val_accuracy: 0.9500\n",
            "Epoch 28/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1641 - accuracy: 0.9392 - val_loss: 0.1474 - val_accuracy: 0.9515\n",
            "Epoch 29/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1625 - accuracy: 0.9394 - val_loss: 0.1392 - val_accuracy: 0.9508\n",
            "Epoch 30/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1572 - accuracy: 0.9443 - val_loss: 0.1297 - val_accuracy: 0.9523\n",
            "Epoch 31/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1538 - accuracy: 0.9443 - val_loss: 0.1272 - val_accuracy: 0.9538\n",
            "Epoch 32/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1523 - accuracy: 0.9448 - val_loss: 0.1270 - val_accuracy: 0.9523\n",
            "Epoch 33/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1503 - accuracy: 0.9464 - val_loss: 0.1261 - val_accuracy: 0.9531\n",
            "Epoch 34/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1491 - accuracy: 0.9456 - val_loss: 0.1243 - val_accuracy: 0.9546\n",
            "Epoch 35/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1473 - accuracy: 0.9464 - val_loss: 0.1216 - val_accuracy: 0.9546\n",
            "Epoch 36/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1459 - accuracy: 0.9471 - val_loss: 0.1187 - val_accuracy: 0.9569\n",
            "Epoch 37/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1450 - accuracy: 0.9484 - val_loss: 0.1191 - val_accuracy: 0.9569\n",
            "Epoch 38/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1462 - accuracy: 0.9492 - val_loss: 0.1199 - val_accuracy: 0.9569\n",
            "Epoch 39/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1475 - accuracy: 0.9461 - val_loss: 0.1209 - val_accuracy: 0.9562\n",
            "Epoch 40/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1494 - accuracy: 0.9477 - val_loss: 0.1145 - val_accuracy: 0.9577\n",
            "Epoch 41/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1439 - accuracy: 0.9484 - val_loss: 0.1124 - val_accuracy: 0.9577\n",
            "Epoch 42/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1400 - accuracy: 0.9497 - val_loss: 0.1106 - val_accuracy: 0.9592\n",
            "Epoch 43/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1356 - accuracy: 0.9510 - val_loss: 0.1140 - val_accuracy: 0.9569\n",
            "Epoch 44/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1357 - accuracy: 0.9528 - val_loss: 0.1084 - val_accuracy: 0.9592\n",
            "Epoch 45/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1340 - accuracy: 0.9528 - val_loss: 0.1074 - val_accuracy: 0.9600\n",
            "Epoch 46/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1334 - accuracy: 0.9523 - val_loss: 0.1082 - val_accuracy: 0.9600\n",
            "Epoch 47/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1309 - accuracy: 0.9538 - val_loss: 0.1097 - val_accuracy: 0.9577\n",
            "Epoch 48/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1301 - accuracy: 0.9543 - val_loss: 0.1076 - val_accuracy: 0.9585\n",
            "Epoch 49/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1302 - accuracy: 0.9548 - val_loss: 0.1079 - val_accuracy: 0.9585\n",
            "Epoch 50/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.1314 - accuracy: 0.9533 - val_loss: 0.1109 - val_accuracy: 0.9577\n",
            "Epoch 51/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1359 - accuracy: 0.9530 - val_loss: 0.1094 - val_accuracy: 0.9577\n",
            "Epoch 52/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1335 - accuracy: 0.9543 - val_loss: 0.1045 - val_accuracy: 0.9577\n",
            "Epoch 53/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1310 - accuracy: 0.9548 - val_loss: 0.1212 - val_accuracy: 0.9669\n",
            "Epoch 54/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.1296 - accuracy: 0.9561 - val_loss: 0.1195 - val_accuracy: 0.9631\n",
            "Epoch 55/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1289 - accuracy: 0.9566 - val_loss: 0.1124 - val_accuracy: 0.9662\n",
            "Epoch 56/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1265 - accuracy: 0.9577 - val_loss: 0.1064 - val_accuracy: 0.9646\n",
            "Epoch 57/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1248 - accuracy: 0.9561 - val_loss: 0.1099 - val_accuracy: 0.9677\n",
            "Epoch 58/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1278 - accuracy: 0.9566 - val_loss: 0.1185 - val_accuracy: 0.9685\n",
            "Epoch 59/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1278 - accuracy: 0.9541 - val_loss: 0.1165 - val_accuracy: 0.9677\n",
            "Epoch 60/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.1258 - accuracy: 0.9556 - val_loss: 0.1037 - val_accuracy: 0.9669\n",
            "Epoch 61/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1201 - accuracy: 0.9589 - val_loss: 0.1008 - val_accuracy: 0.9685\n",
            "Epoch 62/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1155 - accuracy: 0.9597 - val_loss: 0.0933 - val_accuracy: 0.9654\n",
            "Epoch 63/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.1143 - accuracy: 0.9613 - val_loss: 0.0988 - val_accuracy: 0.9708\n",
            "Epoch 64/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.1163 - accuracy: 0.9605 - val_loss: 0.1065 - val_accuracy: 0.9731\n",
            "Epoch 65/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.1138 - accuracy: 0.9605 - val_loss: 0.1024 - val_accuracy: 0.9746\n",
            "Epoch 66/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.1122 - accuracy: 0.9630 - val_loss: 0.0889 - val_accuracy: 0.9708\n",
            "Epoch 67/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.1098 - accuracy: 0.9623 - val_loss: 0.0926 - val_accuracy: 0.9731\n",
            "Epoch 68/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1088 - accuracy: 0.9643 - val_loss: 0.0834 - val_accuracy: 0.9669\n",
            "Epoch 69/2000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 0.1123 - accuracy: 0.9628 - val_loss: 0.0827 - val_accuracy: 0.9638\n",
            "Epoch 70/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.1122 - accuracy: 0.9633 - val_loss: 0.0860 - val_accuracy: 0.9623\n",
            "Epoch 71/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1146 - accuracy: 0.9630 - val_loss: 0.0808 - val_accuracy: 0.9646\n",
            "Epoch 72/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1053 - accuracy: 0.9641 - val_loss: 0.0796 - val_accuracy: 0.9723\n",
            "Epoch 73/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.1041 - accuracy: 0.9674 - val_loss: 0.0781 - val_accuracy: 0.9685\n",
            "Epoch 74/2000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 0.1062 - accuracy: 0.9615 - val_loss: 0.0774 - val_accuracy: 0.9685\n",
            "Epoch 75/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1067 - accuracy: 0.9628 - val_loss: 0.0774 - val_accuracy: 0.9654\n",
            "Epoch 76/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.1062 - accuracy: 0.9641 - val_loss: 0.0756 - val_accuracy: 0.9692\n",
            "Epoch 77/2000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.1024 - accuracy: 0.9651 - val_loss: 0.0754 - val_accuracy: 0.9685\n",
            "Epoch 78/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0986 - accuracy: 0.9677 - val_loss: 0.0742 - val_accuracy: 0.9754\n",
            "Epoch 79/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0983 - accuracy: 0.9692 - val_loss: 0.0738 - val_accuracy: 0.9754\n",
            "Epoch 80/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0954 - accuracy: 0.9713 - val_loss: 0.0725 - val_accuracy: 0.9754\n",
            "Epoch 81/2000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 0.0966 - accuracy: 0.9684 - val_loss: 0.0720 - val_accuracy: 0.9738\n",
            "Epoch 82/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0965 - accuracy: 0.9677 - val_loss: 0.0712 - val_accuracy: 0.9769\n",
            "Epoch 83/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0938 - accuracy: 0.9707 - val_loss: 0.0721 - val_accuracy: 0.9700\n",
            "Epoch 84/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0938 - accuracy: 0.9692 - val_loss: 0.0727 - val_accuracy: 0.9685\n",
            "Epoch 85/2000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 0.0969 - accuracy: 0.9677 - val_loss: 0.0702 - val_accuracy: 0.9700\n",
            "Epoch 86/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0940 - accuracy: 0.9710 - val_loss: 0.0700 - val_accuracy: 0.9808\n",
            "Epoch 87/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.9759 - val_loss: 0.0699 - val_accuracy: 0.9831\n",
            "Epoch 88/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0883 - accuracy: 0.9756 - val_loss: 0.0670 - val_accuracy: 0.9746\n",
            "Epoch 89/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.9710 - val_loss: 0.0665 - val_accuracy: 0.9746\n",
            "Epoch 90/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0891 - accuracy: 0.9720 - val_loss: 0.0656 - val_accuracy: 0.9785\n",
            "Epoch 91/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0883 - accuracy: 0.9743 - val_loss: 0.0713 - val_accuracy: 0.9854\n",
            "Epoch 92/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0876 - accuracy: 0.9751 - val_loss: 0.0690 - val_accuracy: 0.9846\n",
            "Epoch 93/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0891 - accuracy: 0.9720 - val_loss: 0.0707 - val_accuracy: 0.9838\n",
            "Epoch 94/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.9743 - val_loss: 0.0725 - val_accuracy: 0.9838\n",
            "Epoch 95/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0858 - accuracy: 0.9769 - val_loss: 0.0737 - val_accuracy: 0.9831\n",
            "Epoch 96/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0880 - accuracy: 0.9731 - val_loss: 0.0660 - val_accuracy: 0.9846\n",
            "Epoch 97/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0824 - accuracy: 0.9764 - val_loss: 0.0707 - val_accuracy: 0.9846\n",
            "Epoch 98/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0858 - accuracy: 0.9749 - val_loss: 0.0622 - val_accuracy: 0.9838\n",
            "Epoch 99/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0818 - accuracy: 0.9764 - val_loss: 0.0647 - val_accuracy: 0.9854\n",
            "Epoch 100/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0836 - accuracy: 0.9766 - val_loss: 0.0588 - val_accuracy: 0.9800\n",
            "Epoch 101/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0842 - accuracy: 0.9736 - val_loss: 0.0590 - val_accuracy: 0.9762\n",
            "Epoch 102/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0811 - accuracy: 0.9772 - val_loss: 0.0581 - val_accuracy: 0.9838\n",
            "Epoch 103/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0799 - accuracy: 0.9784 - val_loss: 0.0593 - val_accuracy: 0.9838\n",
            "Epoch 104/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0828 - accuracy: 0.9754 - val_loss: 0.0567 - val_accuracy: 0.9800\n",
            "Epoch 105/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0828 - accuracy: 0.9751 - val_loss: 0.0555 - val_accuracy: 0.9808\n",
            "Epoch 106/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0781 - accuracy: 0.9782 - val_loss: 0.0639 - val_accuracy: 0.9877\n",
            "Epoch 107/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0769 - accuracy: 0.9766 - val_loss: 0.0623 - val_accuracy: 0.9869\n",
            "Epoch 108/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0769 - accuracy: 0.9761 - val_loss: 0.0572 - val_accuracy: 0.9862\n",
            "Epoch 109/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9779 - val_loss: 0.0589 - val_accuracy: 0.9862\n",
            "Epoch 110/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0769 - accuracy: 0.9769 - val_loss: 0.0539 - val_accuracy: 0.9846\n",
            "Epoch 111/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0767 - accuracy: 0.9779 - val_loss: 0.0592 - val_accuracy: 0.9738\n",
            "Epoch 112/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0821 - accuracy: 0.9777 - val_loss: 0.0555 - val_accuracy: 0.9777\n",
            "Epoch 113/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0787 - accuracy: 0.9756 - val_loss: 0.0547 - val_accuracy: 0.9862\n",
            "Epoch 114/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0751 - accuracy: 0.9774 - val_loss: 0.0583 - val_accuracy: 0.9869\n",
            "Epoch 115/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0742 - accuracy: 0.9792 - val_loss: 0.0532 - val_accuracy: 0.9862\n",
            "Epoch 116/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0725 - accuracy: 0.9800 - val_loss: 0.0541 - val_accuracy: 0.9869\n",
            "Epoch 117/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0724 - accuracy: 0.9787 - val_loss: 0.0551 - val_accuracy: 0.9877\n",
            "Epoch 118/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0730 - accuracy: 0.9795 - val_loss: 0.0516 - val_accuracy: 0.9862\n",
            "Epoch 119/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0725 - accuracy: 0.9787 - val_loss: 0.0619 - val_accuracy: 0.9862\n",
            "Epoch 120/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0748 - accuracy: 0.9774 - val_loss: 0.0739 - val_accuracy: 0.9831\n",
            "Epoch 121/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0806 - accuracy: 0.9746 - val_loss: 0.0825 - val_accuracy: 0.9769\n",
            "Epoch 122/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0753 - accuracy: 0.9772 - val_loss: 0.0507 - val_accuracy: 0.9862\n",
            "Epoch 123/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0697 - accuracy: 0.9808 - val_loss: 0.0554 - val_accuracy: 0.9869\n",
            "Epoch 124/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0700 - accuracy: 0.9797 - val_loss: 0.0548 - val_accuracy: 0.9885\n",
            "Epoch 125/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0685 - accuracy: 0.9805 - val_loss: 0.0498 - val_accuracy: 0.9846\n",
            "Epoch 126/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0676 - accuracy: 0.9813 - val_loss: 0.0532 - val_accuracy: 0.9885\n",
            "Epoch 127/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0684 - accuracy: 0.9802 - val_loss: 0.0528 - val_accuracy: 0.9777\n",
            "Epoch 128/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0711 - accuracy: 0.9777 - val_loss: 0.0510 - val_accuracy: 0.9823\n",
            "Epoch 129/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0752 - accuracy: 0.9777 - val_loss: 0.0578 - val_accuracy: 0.9862\n",
            "Epoch 130/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0750 - accuracy: 0.9764 - val_loss: 0.0644 - val_accuracy: 0.9862\n",
            "Epoch 131/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0749 - accuracy: 0.9749 - val_loss: 0.0622 - val_accuracy: 0.9854\n",
            "Epoch 132/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0672 - accuracy: 0.9802 - val_loss: 0.0668 - val_accuracy: 0.9854\n",
            "Epoch 133/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.0529 - val_accuracy: 0.9869\n",
            "Epoch 134/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0692 - accuracy: 0.9792 - val_loss: 0.0496 - val_accuracy: 0.9831\n",
            "Epoch 135/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0715 - accuracy: 0.9772 - val_loss: 0.0528 - val_accuracy: 0.9777\n",
            "Epoch 136/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0696 - accuracy: 0.9787 - val_loss: 0.0488 - val_accuracy: 0.9823\n",
            "Epoch 137/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0652 - accuracy: 0.9808 - val_loss: 0.0504 - val_accuracy: 0.9869\n",
            "Epoch 138/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0632 - accuracy: 0.9820 - val_loss: 0.0485 - val_accuracy: 0.9846\n",
            "Epoch 139/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0642 - accuracy: 0.9808 - val_loss: 0.0479 - val_accuracy: 0.9854\n",
            "Epoch 140/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0628 - accuracy: 0.9813 - val_loss: 0.0519 - val_accuracy: 0.9862\n",
            "Epoch 141/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0631 - accuracy: 0.9820 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 142/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0628 - accuracy: 0.9813 - val_loss: 0.0490 - val_accuracy: 0.9846\n",
            "Epoch 143/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0632 - accuracy: 0.9823 - val_loss: 0.0487 - val_accuracy: 0.9846\n",
            "Epoch 144/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.0501 - val_accuracy: 0.9869\n",
            "Epoch 145/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0677 - accuracy: 0.9810 - val_loss: 0.0730 - val_accuracy: 0.9808\n",
            "Epoch 146/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0728 - accuracy: 0.9759 - val_loss: 0.0539 - val_accuracy: 0.9854\n",
            "Epoch 147/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0627 - accuracy: 0.9795 - val_loss: 0.0460 - val_accuracy: 0.9854\n",
            "Epoch 148/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0612 - accuracy: 0.9813 - val_loss: 0.0578 - val_accuracy: 0.9862\n",
            "Epoch 149/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0655 - accuracy: 0.9795 - val_loss: 0.0605 - val_accuracy: 0.9854\n",
            "Epoch 150/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0675 - accuracy: 0.9792 - val_loss: 0.0458 - val_accuracy: 0.9854\n",
            "Epoch 151/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0707 - accuracy: 0.9802 - val_loss: 0.0492 - val_accuracy: 0.9785\n",
            "Epoch 152/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0704 - accuracy: 0.9779 - val_loss: 0.0500 - val_accuracy: 0.9785\n",
            "Epoch 153/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0684 - accuracy: 0.9792 - val_loss: 0.0618 - val_accuracy: 0.9746\n",
            "Epoch 154/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0702 - accuracy: 0.9790 - val_loss: 0.0450 - val_accuracy: 0.9846\n",
            "Epoch 155/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0606 - accuracy: 0.9826 - val_loss: 0.0476 - val_accuracy: 0.9885\n",
            "Epoch 156/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0599 - accuracy: 0.9823 - val_loss: 0.0530 - val_accuracy: 0.9869\n",
            "Epoch 157/2000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 0.0616 - accuracy: 0.9826 - val_loss: 0.0497 - val_accuracy: 0.9885\n",
            "Epoch 158/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0614 - accuracy: 0.9828 - val_loss: 0.0467 - val_accuracy: 0.9862\n",
            "Epoch 159/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.9820 - val_loss: 0.0463 - val_accuracy: 0.9831\n",
            "Epoch 160/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0602 - accuracy: 0.9823 - val_loss: 0.0485 - val_accuracy: 0.9877\n",
            "Epoch 161/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 0.0484 - val_accuracy: 0.9885\n",
            "Epoch 162/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0593 - accuracy: 0.9826 - val_loss: 0.0447 - val_accuracy: 0.9831\n",
            "Epoch 163/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0623 - accuracy: 0.9820 - val_loss: 0.0447 - val_accuracy: 0.9838\n",
            "Epoch 164/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0602 - accuracy: 0.9818 - val_loss: 0.0492 - val_accuracy: 0.9885\n",
            "Epoch 165/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0594 - accuracy: 0.9836 - val_loss: 0.0530 - val_accuracy: 0.9869\n",
            "Epoch 166/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0630 - accuracy: 0.9808 - val_loss: 0.0472 - val_accuracy: 0.9869\n",
            "Epoch 167/2000\n",
            "8/8 [==============================] - 0s 13ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0440 - val_accuracy: 0.9846\n",
            "Epoch 168/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.9815 - val_loss: 0.0440 - val_accuracy: 0.9831\n",
            "Epoch 169/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0589 - accuracy: 0.9841 - val_loss: 0.0446 - val_accuracy: 0.9862\n",
            "Epoch 170/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0578 - accuracy: 0.9831 - val_loss: 0.0445 - val_accuracy: 0.9862\n",
            "Epoch 171/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0586 - accuracy: 0.9826 - val_loss: 0.0441 - val_accuracy: 0.9846\n",
            "Epoch 172/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0583 - accuracy: 0.9846 - val_loss: 0.0458 - val_accuracy: 0.9892\n",
            "Epoch 173/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0600 - accuracy: 0.9828 - val_loss: 0.0524 - val_accuracy: 0.9869\n",
            "Epoch 174/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0655 - accuracy: 0.9797 - val_loss: 0.0748 - val_accuracy: 0.9808\n",
            "Epoch 175/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0659 - accuracy: 0.9815 - val_loss: 0.0634 - val_accuracy: 0.9846\n",
            "Epoch 176/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0682 - accuracy: 0.9792 - val_loss: 0.0560 - val_accuracy: 0.9862\n",
            "Epoch 177/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0649 - accuracy: 0.9805 - val_loss: 0.0436 - val_accuracy: 0.9885\n",
            "Epoch 178/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0685 - accuracy: 0.9795 - val_loss: 0.0431 - val_accuracy: 0.9808\n",
            "Epoch 179/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0624 - accuracy: 0.9831 - val_loss: 0.0424 - val_accuracy: 0.9846\n",
            "Epoch 180/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0591 - accuracy: 0.9820 - val_loss: 0.0427 - val_accuracy: 0.9869\n",
            "Epoch 181/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0565 - accuracy: 0.9838 - val_loss: 0.0427 - val_accuracy: 0.9877\n",
            "Epoch 182/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0573 - accuracy: 0.9846 - val_loss: 0.0428 - val_accuracy: 0.9862\n",
            "Epoch 183/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0563 - accuracy: 0.9820 - val_loss: 0.0427 - val_accuracy: 0.9862\n",
            "Epoch 184/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0579 - accuracy: 0.9820 - val_loss: 0.0425 - val_accuracy: 0.9831\n",
            "Epoch 185/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9818 - val_loss: 0.0430 - val_accuracy: 0.9823\n",
            "Epoch 186/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0564 - accuracy: 0.9828 - val_loss: 0.0433 - val_accuracy: 0.9877\n",
            "Epoch 187/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0560 - accuracy: 0.9826 - val_loss: 0.0449 - val_accuracy: 0.9885\n",
            "Epoch 188/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9841 - val_loss: 0.0424 - val_accuracy: 0.9862\n",
            "Epoch 189/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0580 - accuracy: 0.9820 - val_loss: 0.0432 - val_accuracy: 0.9869\n",
            "Epoch 190/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0557 - accuracy: 0.9838 - val_loss: 0.0451 - val_accuracy: 0.9869\n",
            "Epoch 191/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0572 - accuracy: 0.9836 - val_loss: 0.0525 - val_accuracy: 0.9869\n",
            "Epoch 192/2000\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.0428 - val_accuracy: 0.9869\n",
            "Epoch 193/2000\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 0.0582 - accuracy: 0.9815 - val_loss: 0.0461 - val_accuracy: 0.9877\n",
            "Epoch 194/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0576 - accuracy: 0.9831 - val_loss: 0.0441 - val_accuracy: 0.9877\n",
            "Epoch 195/2000\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 0.0574 - accuracy: 0.9841 - val_loss: 0.0459 - val_accuracy: 0.9877\n",
            "Epoch 196/2000\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 0.0578 - accuracy: 0.9833 - val_loss: 0.0436 - val_accuracy: 0.9831\n",
            "Epoch 197/2000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 0.0588 - accuracy: 0.9805 - val_loss: 0.0456 - val_accuracy: 0.9800\n",
            "Epoch 198/2000\n",
            "8/8 [==============================] - 0s 14ms/step - loss: 0.0600 - accuracy: 0.9838 - val_loss: 0.0517 - val_accuracy: 0.9777\n",
            "Epoch 199/2000\n",
            "8/8 [==============================] - 0s 12ms/step - loss: 0.0649 - accuracy: 0.9784 - val_loss: 0.0454 - val_accuracy: 0.9808\n",
            "41/41 [==============================] - 0s 4ms/step - loss: 0.0930 - accuracy: 0.9715\n",
            "Test accuracy 0.9715384840965271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "score=model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', score[1A])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sl6agcnB_op",
        "outputId": "f3eff217-588e-4f71-8084-48619eaedf10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 5ms/step - loss: 0.0930 - accuracy: 0.9715\n",
            "Test accuracy: 0.9715384840965271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#주택 가격 예측하기\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns   #그림 그리기\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/Deeplearning_study/house_train.csv')\n",
        "\n",
        "df= pd.get_dummies(df) #원핫 인코딩 (문자열 -> 숫자열)\n",
        "\n",
        "df= df.fillna(df.mean())  #평균치로 null인 자리를 채워줌\n",
        "\n",
        "df_corr= df.corr() #데이터 사이의 상관관계를 저장합니다. \n",
        "\n",
        "df_corr_sort = df_corr.sort_values('SalePrice', ascending=False) #집 값과 관련이 큰 것부터 순서대로 저장합니다.\n",
        "\n",
        "cols_train = ['OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF']    # 집 값을 제외한 나머지 열을 저장합니다.\n",
        "X_train_pre= df[cols_train]\n",
        "\n",
        "y= df['SalePrice'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_train_pre, y, test_size=0.2)\n",
        "\n",
        "#모델의 구조를 설정합니다.\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu'))\n",
        "model.add(Dense(30, activation='relu'))\n",
        "model.add(Dense(40, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()\n",
        "\n",
        "#모델을 실행합니다.\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "#20번 이상 결과가 향상되지 않으면 자동으로 중단되게끔 합니다.\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=20)\n",
        "\n",
        "#모델의 이름을 정합니다.\n",
        "modelpath = \"/content/Deeplearning_study/Ch15-house.hdf5\"\n",
        "\n",
        "#최적화 모델을 업데이트하고 저장합니다.\n",
        "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)\n",
        "\n",
        "#실행 관련 설정을 하는 부분입니다., 전체의 20%를 검증셋으로 설정합니다.\n",
        "history = model.fit(X_train, y_train, validation_split=0.25, epochs=2000, batch_size=32, callbacks=[early_stopping_callback, checkpointer])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2vhsu9_Gip9",
        "outputId": "5154cdd3-bc4f-4c8b-9a30-2bed9098093b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_46 (Dense)            (None, 10)                50        \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 30)                330       \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,661\n",
            "Trainable params: 1,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/2000\n",
            "28/28 [==============================] - 1s 11ms/step - loss: 38038466560.0000 - val_loss: 38231330816.0000\n",
            "Epoch 2/2000\n",
            "28/28 [==============================] - 0s 6ms/step - loss: 37379801088.0000 - val_loss: 37282697216.0000\n",
            "Epoch 3/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 35971813376.0000 - val_loss: 35098411008.0000\n",
            "Epoch 4/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 32746856448.0000 - val_loss: 30411886592.0000\n",
            "Epoch 5/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 26619152384.0000 - val_loss: 22311641088.0000\n",
            "Epoch 6/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 17116430336.0000 - val_loss: 12040859648.0000\n",
            "Epoch 7/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 7425868800.0000 - val_loss: 4914238464.0000\n",
            "Epoch 8/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 2509078016.0000 - val_loss: 3853119488.0000\n",
            "Epoch 9/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1969378304.0000 - val_loss: 4012851456.0000\n",
            "Epoch 10/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1958076032.0000 - val_loss: 3925120256.0000\n",
            "Epoch 11/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1959414016.0000 - val_loss: 3952997376.0000\n",
            "Epoch 12/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1956953856.0000 - val_loss: 3931789568.0000\n",
            "Epoch 13/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1953808640.0000 - val_loss: 3952609536.0000\n",
            "Epoch 14/2000\n",
            "28/28 [==============================] - 0s 5ms/step - loss: 1952624000.0000 - val_loss: 3947304704.0000\n",
            "Epoch 15/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1950806016.0000 - val_loss: 3947423232.0000\n",
            "Epoch 16/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1947800576.0000 - val_loss: 3973210112.0000\n",
            "Epoch 17/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1946850432.0000 - val_loss: 3942049280.0000\n",
            "Epoch 18/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1953308544.0000 - val_loss: 3980188928.0000\n",
            "Epoch 19/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1946064000.0000 - val_loss: 3939286016.0000\n",
            "Epoch 20/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1946206464.0000 - val_loss: 3950216192.0000\n",
            "Epoch 21/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1945330176.0000 - val_loss: 3996680704.0000\n",
            "Epoch 22/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1941741952.0000 - val_loss: 3974083328.0000\n",
            "Epoch 23/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1945387264.0000 - val_loss: 3991256320.0000\n",
            "Epoch 24/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1944536064.0000 - val_loss: 4000237568.0000\n",
            "Epoch 25/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1937812736.0000 - val_loss: 3959269120.0000\n",
            "Epoch 26/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1937293440.0000 - val_loss: 3981211904.0000\n",
            "Epoch 27/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1938032384.0000 - val_loss: 3956103936.0000\n",
            "Epoch 28/2000\n",
            "28/28 [==============================] - 0s 4ms/step - loss: 1936765056.0000 - val_loss: 3976562944.0000\n"
          ]
        }
      ]
    }
  ]
}